{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Information Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv(\"heart-disease-uci.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(.5 * (1 - .5)))\n",
    "df_selection = sel.fit_transform(df)\n",
    "df_selection.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Heart Disease Dataset Cleveland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# seed for reproducing same results\n",
    "seed = 9\n",
    "np.random.seed(seed)\n",
    "\n",
    "# load heart disease dataset\n",
    "dataset = np.loadtxt('heart-disease-uci.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "# split into input and output variables\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]\n",
    "\n",
    "# split the data into training (90%) and testing (10%)\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.10, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "model_scaler= MinMaxScaler().fit(X_train)\n",
    "X_train_scale = model_scaler.transform(X_train)\n",
    "X_test_scale = model_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4375    , 0.        , 0.66666667, ..., 0.5       , 0.        ,\n",
       "        0.66666667],\n",
       "       [0.60416667, 1.        , 0.        , ..., 0.5       , 0.75      ,\n",
       "        1.        ],\n",
       "       [0.375     , 1.        , 0.66666667, ..., 1.        , 0.        ,\n",
       "        0.66666667],\n",
       "       ...,\n",
       "       [0.29166667, 1.        , 0.        , ..., 0.5       , 1.        ,\n",
       "        1.        ],\n",
       "       [0.39583333, 1.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.66666667],\n",
       "       [0.375     , 1.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.66666667]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6371 - accuracy: 0.7059 - val_loss: 0.5649 - val_accuracy: 0.8387\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5158 - accuracy: 0.8015 - val_loss: 0.4649 - val_accuracy: 0.8387\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8235 - val_loss: 0.4423 - val_accuracy: 0.7419\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8382 - val_loss: 0.4176 - val_accuracy: 0.8387\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3577 - accuracy: 0.8493 - val_loss: 0.4653 - val_accuracy: 0.8065\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3369 - accuracy: 0.8713 - val_loss: 0.5135 - val_accuracy: 0.7742\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3209 - accuracy: 0.8713 - val_loss: 0.4591 - val_accuracy: 0.8387\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.8419 - val_loss: 0.5215 - val_accuracy: 0.7742\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8603 - val_loss: 0.5299 - val_accuracy: 0.7097\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2968 - accuracy: 0.8934 - val_loss: 0.4496 - val_accuracy: 0.8387\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2957 - accuracy: 0.8787 - val_loss: 0.5697 - val_accuracy: 0.7097\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2938 - accuracy: 0.8897 - val_loss: 0.4609 - val_accuracy: 0.8387\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2803 - accuracy: 0.8971 - val_loss: 0.5405 - val_accuracy: 0.7419\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2725 - accuracy: 0.9007 - val_loss: 0.4982 - val_accuracy: 0.8065\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2581 - accuracy: 0.9007 - val_loss: 0.5554 - val_accuracy: 0.7419\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.9044 - val_loss: 0.5146 - val_accuracy: 0.8065\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2453 - accuracy: 0.9191 - val_loss: 0.5511 - val_accuracy: 0.8065\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2363 - accuracy: 0.9154 - val_loss: 0.6117 - val_accuracy: 0.7097\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2439 - accuracy: 0.9007 - val_loss: 0.4604 - val_accuracy: 0.8065\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2228 - accuracy: 0.9228 - val_loss: 0.5640 - val_accuracy: 0.7742\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2116 - accuracy: 0.9338 - val_loss: 0.5742 - val_accuracy: 0.7097\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1982 - accuracy: 0.9301 - val_loss: 0.5656 - val_accuracy: 0.7742\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1938 - accuracy: 0.9338 - val_loss: 0.5231 - val_accuracy: 0.8065\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1830 - accuracy: 0.9412 - val_loss: 0.6227 - val_accuracy: 0.7097\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1778 - accuracy: 0.9301 - val_loss: 0.6636 - val_accuracy: 0.7097\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1804 - accuracy: 0.9412 - val_loss: 0.7334 - val_accuracy: 0.7097\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1772 - accuracy: 0.9412 - val_loss: 0.5973 - val_accuracy: 0.7419\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1537 - accuracy: 0.9449 - val_loss: 0.6766 - val_accuracy: 0.7097\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1512 - accuracy: 0.9559 - val_loss: 0.6233 - val_accuracy: 0.7419\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9559 - val_loss: 0.5864 - val_accuracy: 0.7419\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1480 - accuracy: 0.9485 - val_loss: 0.8545 - val_accuracy: 0.7097\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9118 - val_loss: 0.7846 - val_accuracy: 0.7419\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 0.9596 - val_loss: 0.4629 - val_accuracy: 0.8710\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1599 - accuracy: 0.9412 - val_loss: 0.6867 - val_accuracy: 0.7097\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1226 - accuracy: 0.9632 - val_loss: 0.6289 - val_accuracy: 0.7097\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9632 - val_loss: 0.5888 - val_accuracy: 0.7419\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.9706 - val_loss: 0.8616 - val_accuracy: 0.7097\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1037 - accuracy: 0.9669 - val_loss: 0.8251 - val_accuracy: 0.7097\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1039 - accuracy: 0.9632 - val_loss: 0.6685 - val_accuracy: 0.7419\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0903 - accuracy: 0.9706 - val_loss: 0.8053 - val_accuracy: 0.7097\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0869 - accuracy: 0.9706 - val_loss: 0.6351 - val_accuracy: 0.7419\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0852 - accuracy: 0.9743 - val_loss: 0.5440 - val_accuracy: 0.8065\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0900 - accuracy: 0.9706 - val_loss: 0.6063 - val_accuracy: 0.7742\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0952 - accuracy: 0.9706 - val_loss: 1.2267 - val_accuracy: 0.6774\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1007 - accuracy: 0.9596 - val_loss: 0.6833 - val_accuracy: 0.7419\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9669 - val_loss: 0.4610 - val_accuracy: 0.8387\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1030 - accuracy: 0.9559 - val_loss: 0.6740 - val_accuracy: 0.7742\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9706 - val_loss: 1.1577 - val_accuracy: 0.7097\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1118 - accuracy: 0.9449 - val_loss: 0.6597 - val_accuracy: 0.7419\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.9743 - val_loss: 0.6055 - val_accuracy: 0.8065\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0884 - accuracy: 0.9706 - val_loss: 0.9307 - val_accuracy: 0.7097\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0858 - accuracy: 0.9706 - val_loss: 0.7233 - val_accuracy: 0.7097\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1129 - accuracy: 0.9522 - val_loss: 0.5479 - val_accuracy: 0.7419\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0954 - accuracy: 0.9669 - val_loss: 0.8570 - val_accuracy: 0.7097\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0877 - accuracy: 0.9596 - val_loss: 1.0900 - val_accuracy: 0.7097\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0910 - accuracy: 0.9559 - val_loss: 0.5241 - val_accuracy: 0.8387\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0993 - accuracy: 0.9632 - val_loss: 0.9526 - val_accuracy: 0.7419\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9706 - val_loss: 0.9283 - val_accuracy: 0.7419\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0689 - accuracy: 0.9706 - val_loss: 0.6893 - val_accuracy: 0.7742\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0739 - accuracy: 0.9706 - val_loss: 1.1316 - val_accuracy: 0.7097\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.9816 - val_loss: 0.7302 - val_accuracy: 0.7419\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0447 - accuracy: 0.9853 - val_loss: 1.0485 - val_accuracy: 0.7419\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 0.9853 - val_loss: 0.7328 - val_accuracy: 0.8065\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0421 - accuracy: 0.9853 - val_loss: 0.9108 - val_accuracy: 0.7419\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0309 - accuracy: 0.9926 - val_loss: 0.6610 - val_accuracy: 0.7742\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9816 - val_loss: 1.0339 - val_accuracy: 0.7097\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9926 - val_loss: 0.8025 - val_accuracy: 0.7742\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9926 - val_loss: 0.9585 - val_accuracy: 0.7419\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9853 - val_loss: 0.6968 - val_accuracy: 0.7742\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9779 - val_loss: 1.1410 - val_accuracy: 0.6774\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.9816 - val_loss: 0.6237 - val_accuracy: 0.7742\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.9853 - val_loss: 0.9420 - val_accuracy: 0.7097\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.9853 - val_loss: 0.7676 - val_accuracy: 0.7742\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9926 - val_loss: 0.9978 - val_accuracy: 0.7097\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9926 - val_loss: 0.8907 - val_accuracy: 0.7419\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9926 - val_loss: 0.9299 - val_accuracy: 0.7419\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.9963 - val_loss: 1.0371 - val_accuracy: 0.7419\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0215 - accuracy: 0.9963 - val_loss: 0.9663 - val_accuracy: 0.7419\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0249 - accuracy: 0.9890 - val_loss: 1.1276 - val_accuracy: 0.7097\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.9926 - val_accuracy: 0.7419\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.9601 - val_accuracy: 0.7742\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9926 - val_loss: 0.9891 - val_accuracy: 0.7742\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9926 - val_loss: 1.1388 - val_accuracy: 0.7419\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 0.8887 - val_accuracy: 0.8387\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9963 - val_loss: 0.9959 - val_accuracy: 0.8065\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.9926 - val_loss: 0.9121 - val_accuracy: 0.8387\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9853 - val_loss: 1.5486 - val_accuracy: 0.7419\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9926 - val_loss: 0.8155 - val_accuracy: 0.7742\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9853 - val_loss: 1.4839 - val_accuracy: 0.7097\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9890 - val_loss: 0.8802 - val_accuracy: 0.7742\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9963 - val_loss: 1.6439 - val_accuracy: 0.7097\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0656 - accuracy: 0.9816 - val_loss: 0.7498 - val_accuracy: 0.8387\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.9743 - val_loss: 0.9247 - val_accuracy: 0.7742\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0630 - accuracy: 0.9779 - val_loss: 1.6181 - val_accuracy: 0.7419\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.9632 - val_loss: 0.6803 - val_accuracy: 0.9032\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9706 - val_loss: 0.9927 - val_accuracy: 0.7419\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9890 - val_loss: 1.0450 - val_accuracy: 0.7419\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 1.3399 - val_accuracy: 0.7097\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9853 - val_loss: 1.1652 - val_accuracy: 0.7419\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9926 - val_loss: 1.1609 - val_accuracy: 0.7742\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.9963\n",
      "Accuracy Training: 99.63%\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1609 - accuracy: 0.7742\n",
      "Accuracy Testing: 77.42%\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(150, input_dim=13, activation='relu'))\n",
    "model.add(Dense(140, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) # ada 2 kelas, multiclass softmax\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train_scale, Y_train, validation_data=(X_test_scale, Y_test), epochs=100, verbose=1)\n",
    "# evaluate the model training\n",
    "scores = model.evaluate(X_train_scale, Y_train)\n",
    "print(\"Accuracy Training: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "# evaluate the model testing\n",
    "scores = model.evaluate(X_test_scale, Y_test)\n",
    "print(\"Accuracy Testing: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model Traning History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Distribution of Classes (PDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf(x, std, mean):\n",
    "    cons = 1.0 / np.sqrt(2*np.pi*(std**2))\n",
    "    pdf_normal_dist = cons*np.exp(-((x-mean)**2)/(2.0*(std**2)))\n",
    "    return pdf_normal_dist\n",
    "\n",
    "x = np.linspace(0, 1, num=303)\n",
    "normal_pdf = pdf(x,0.1,0.4)\n",
    "disease_pdf = pdf(x,0.1,0.6)\n",
    "\n",
    "#let’s create a function to plot the distributions.\n",
    "def plot_pdf(normal_pdf, disease_pdf, ax):\n",
    "    ax.fill(x, normal_pdf, \"g\", alpha=0.5)\n",
    "    ax.fill(x, disease_pdf,\"r\", alpha=0.5)\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,5])\n",
    "    ax.set_title(\"Probability Distribution\", fontsize=14)\n",
    "    ax.set_ylabel('Counts', fontsize=12)\n",
    "    ax.set_xlabel('P(X=\"Heart Disease\")', fontsize=12)\n",
    "    ax.legend([\"Normal\",\"Heart Disease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let’s use this plot_pdf function to generate the plot\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "plot_pdf(normal_pdf, disease_pdf, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the ROC Plot Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(normal_pdf, disease_pdf, ax):\n",
    "    #Total\n",
    "    total_disease = np.sum(disease_pdf)\n",
    "    total_normal = np.sum(normal_pdf)\n",
    "    #Cumulative sum\n",
    "    cum_TP = 0\n",
    "    cum_FP = 0\n",
    "    #TPR and FPR list initialization\n",
    "    TPR_list=[]\n",
    "    FPR_list=[]\n",
    "    #Iteratre through all values of x\n",
    "    for i in range(len(x)):\n",
    "        #We are only interested in non-zero values of disease\n",
    "        if disease_pdf[i]>0:\n",
    "            cum_TP+=disease_pdf[len(x)-1-i]\n",
    "            cum_FP+=normal_pdf[len(x)-1-i]\n",
    "        FPR=cum_FP/total_normal\n",
    "        TPR=cum_TP/total_disease\n",
    "        TPR_list.append(TPR)\n",
    "        FPR_list.append(FPR)\n",
    "    #Calculating AUC, taking the 303 timesteps into account\n",
    "    auc=np.sum(TPR_list)/303\n",
    "    #Plotting final ROC curve\n",
    "    ax.plot(FPR_list, TPR_list)\n",
    "    ax.plot(x,x, \"--\")\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_title(\"ROC Curve\", fontsize=14)\n",
    "    ax.set_ylabel('True Positive Rate (TPR)', fontsize=12)\n",
    "    ax.set_xlabel('False Positive Rate (FPR)', fontsize=12)\n",
    "    ax.grid()\n",
    "    ax.legend([\"AUC=%.3f\"%auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_roc function to generate the plot\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "plot_roc(normal_pdf, disease_pdf, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Prediction (For New Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seed for reproducing same results\n",
    "seed = 9\n",
    "np.random.seed(seed)\n",
    "\n",
    "# load heart disease dataset\n",
    "dataset = np.loadtxt('heart-disease-uci.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "# split into input and output variables\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(14, input_dim=13, init='uniform', activation='relu'))\n",
    "model.add(Dense(10, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "history=model.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=158, batch_size=5, verbose=0)\n",
    "\n",
    "# calculate predictions\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
